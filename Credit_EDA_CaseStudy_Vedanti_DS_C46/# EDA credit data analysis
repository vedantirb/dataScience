# EDA credit data analysis

This case study aims to identify patterns which indicate if a client has difficulty paying their instalments which may be used for taking actions such as denying the loan, reducing the amount of loan, lending (to risky applicants) at a higher interest rate, etc.  
This will ensure that the consumers capable of repaying the loan are not rejected. Identification of such applicants using EDA is the aim of this case study.

<a href="#1.-applications-dataFrame">applications dataFrame</a>  
<a href="#3.-Find-missing-value-Threshold">Find missing value Threshold</a>  
<a href="#2.-previous_applications-dataFrame">previous_applications dataFrame</a>

**Importing requried modules**

# importing requried modules
import pandas as pd
import numpy as np
import seaborn as sn
import matplotlib.pyplot as plt
import warnings

warnings.filterwarnings("ignore")


**Importing dataFrames**

applications = pd.read_csv("../Credit_EDA_CaseStudy_Vedanti_DS_C46/Credit_EDA_Case_Study_datasets/application_data.csv")
pre_applications = pd.read_csv("../Credit_EDA_CaseStudy_Vedanti_DS_C46/Credit_EDA_Case_Study_datasets/previous_application.csv")

#set max columns to 122 
pd.set_option("display.max_columns", 122)


## 1. applications dataFrame

**Understanding  data structure for applications dataFrame**

#check shape of dataFrame 
print(applications.shape) 

# head to check few data from applications dataFrame
applications.head()

# check each data type and null values for applications dataFrame
applications.info(verbose=True, show_counts=True)

# Describe of applications dataFrame 
# apply function to supress scientific notation from each column's statistics
applications.describe().apply(lambda col: col.apply('{0:.4f}'.format))


## 3. Find missing value Threshold

pd.set_option('display.max_rows', None)

# Missing values percentages in applications dataframe
app_row, col = applications.shape
null_count = applications.isnull().sum()
null_percentage = round((applications.isnull().sum()/app_row)*100,2)
null_display = pd.DataFrame({"null percentage": null_percentage, "null count": null_count})
null_display.sort_values(by = "null percentage", ascending=False)

**Clearing Data**

# clear columns who's missing data > 30 %
# column name to be deleted 
col_to_del = null_display[null_display["null percentage"] > 35].index.to_list()
print("No of column to be deleted:", len(col_to_del))
print("Column's label:" , col_to_del)
applications.drop(columns = col_to_del, axis=1, inplace=True)


print(applications.shape)
applications.head()

# after deletion of few columns finding columns who's null values <35 and >13 
app_row, col = applications.shape
null_count = applications.isnull().sum()
null_percentage = round((applications.isnull().sum()/app_row)*100,2)

null_display = pd.DataFrame({"null percentage": null_percentage, "null count": null_count})
null_display.sort_values(by = "null percentage", ascending=False)
null_below_35 = null_display[(null_display["null percentage"] < 35) & (null_display["null count"] > 1)]
print(null_below_35.shape)
null_below_35.sort_values(by="null percentage", ascending = False)

# observation for dtypes
dt = applications[null_below_35.index.to_list()]
dt.info()

# catogorical OCCUPATION_TYPE  has 31.35 % null values
applications["OCCUPATION_TYPE"].value_counts()

# find num of unique value
applications["OCCUPATION_TYPE"].nunique()
#impute null values with unknown category
applications["OCCUPATION_TYPE"].fillna(value="Unknown", inplace=True)


# impute gender value
applications["CODE_GENDER"].value_counts()
applications["CODE_GENDER"].nunique()
applications["CODE_GENDER"].value_counts()

# Female applicants are more and even missing values are very less 
# And so we will impute missing Gender value with Female
applications["CODE_GENDER"].replace("XNA","F", inplace=True)
applications["CODE_GENDER"].value_counts()

## 2. previous_applications dataFrame

**Understanding  data structure for pre_applications dataFrame**

#check shape of dataFrame 
print(pre_applications.shape) 

# head to check few data from previous_applications dataFrame
pre_applications.head()

# check each data type and null values for previous_applications dataset
pre_applications.info(verbose=True, show_counts=True)

# Describe of previous_applications dataFrame
# apply function to supress scientific notation from each column's statistics

pre_applications.describe().apply(lambda col: col.apply('{0:.4f}'.format))


# Missing values percentages in pre_applications dataframe
pre_row, col = pre_applications.shape
round((pre_applications.isnull().sum()/pre_row)*100, 2)